# 2018.8.30
---
## 1. 分词与命名实体识别
* `汉语分词`：自动识别词边界，将汉字串切分为正确的词串，`命名实体的自动识别`也是汉语分词的关键问题和热点问题,在汉语分词中对命名实体词汇的识别处理是指将命名实体中可`独立成词`的切分单位正确地识别出来，而不是指识别整个实体的左右边界<br>
* `词性标注`是在给定句子中判定每个词的语法范畴，确定其词性并加以标注的过程<br>
* 在`分词`和`词性标注`的基础上进行命名实体识别的过程就是对部分词语进行拆分、组合（确定实体边界）和重新分类（确定实体类别）的过程，最后输出一个最优的“词形／词性”序列。<br>
* `中文命名实体识别`往往是在`分词`之后进行的，将给定的文本首先进行分词处理，然后对人名、简单地名和简单的组织机构名进行识别，最后识别复合地名和复合组织机构名，而分词系统往往在命名实体词汇上出现`分词错误`，特别是音译词汇。`分词错误`会直接造成命名实体的部分识别或者未识别。<br>
* 虽然现有的中文分词系统有较高的水平（Ｆ-score可以达到95％以上），但是在命名实体词汇的切分中常常出现错误，这主要是因为`命名实体词汇`往往是`未登录词`（OOV），而OOV造成的分词`精度失落`至少比分词歧义大５倍以上。<br>
* 此外，中文分词并没有统一的标准，现有的分词系统基本上是采用“结合紧密，使用稳定”作为分词粒度的界定标准，而实际上不同的应用，对于`分词粒度`有着不同的需求。<br>

## 2. CRF Layer on the Top of BiLSTM
[如何用简单易懂的例子解释条件随机场（CRF）模型？它和HMM有什么区别](https://www.zhihu.com/question/35866596/answer/236886066)<br>

[通俗理解BiLSTM-CRF命名实体识别模型中的CRF层](https://www.cnblogs.com/createMoMo/p/7529885.html)<br>

[github代码](https://github.com/createmomo/CRF-Layer-on-the-Top-of-BiLSTM)<br>
>像RNN、LSTM、BILSTM这些模型，它们在`序列建模`上很强大，它们能够`捕获长远的上下文信息`，此外还具备神经网络`拟合非线性的能力`，这些都是`crf无法超越`的地方<br>

1. What if we DO NOT have the CRF layer<br>
![](https://createmomo.github.io/2017/09/12/CRF_Layer_on_the_Top_of_BiLSTM_1/CRF-LAYER-3.jpg)<br>
![](https://createmomo.github.io/2017/09/12/CRF_Layer_on_the_Top_of_BiLSTM_1/CRF-LAYER-4.jpg)<br>
显然，这次输出无效，“I-Organization I-Person”和“B-Organization I-Person”。<br>
2. CRF layer can learn constrains from training data<br>
![](https://github.com/qiuxingfa/picture_/blob/master/2018.8.30/043f8d915263775199b02b4f1df6c11.png)<br>
3. LossFunction
![](https://github.com/qiuxingfa/picture_/blob/master/2018.8.30/df31217338bbfef1d0c67c82cf47e9f.png)<br>
![](https://github.com/qiuxingfa/picture_/blob/master/2018.8.30/7750a22ca813be7ec72da3c7caa67f9.png)<br>
4. The total score of all the paths<br>
[totalscore具体推导过程](https://createmomo.github.io/2017/11/11/CRF-Layer-on-the-Top-of-BiLSTM-5/)<br>
使用梯度下降等优化方法来求解参数。在这个过程中，我们要最大化真实标记序列的概率，也就训练了转移概率矩阵A和BiLSTM中的参数。<br>
5. Infer the labels for a new sentence<br>
预测的时候，根据训练好的参数求出所有可能的y序列对应的s得分（这里应该也可以利用维特比算法）,然后取最好的得分做为预测结果输出。<br>

## 3. Character-Based LSTM-CRF with Radical-Level Features for Chinese Named Entity Recognition
[新华字典在线](http://tool.httpcn.com/Zi/)<br>
![](https://github.com/qiuxingfa/picture_/blob/master/2018.8.30/0cb0211982bcd371d273a1e039f15a0.png)<br>

* We test our model on MSRA data set of the third SIGHAN Bakeoff Chinese named entity recognition task.<br>
![](https://github.com/qiuxingfa/picture_/blob/master/2018.8.30/e0ef7a6d6b7f389cc7c982a3fd369dc.png)<br>
* We find that `radical-level LSTM` gives us an improvement of +0.53 in F1 with random initialized character embeddings. It is evident that radical-level information is `effective` for Chinese<br>
* there are few characters initialized with random embeddings.So we `do not find further improvement` using both `radical-level LSTM` and `well pretrained character embeddings`<br>

## 4. End-to-end Sequence Labeling via Bi-directional LSTM-CNNs-CRF
* CNN is an effective approach to extract `morphological` information (like the `prefix or suffix` of a word) from characters of words and encode it into neural representations.<br>
![](https://github.com/qiuxingfa/picture_/blob/master/2018.8.30/b8c6ab7c3ea67d76b79aef11be5c6c5.png)<br>
![](https://github.com/qiuxingfa/picture_/blob/master/2018.8.30/df2ebf34fd3bf7b032ca9698c475148.png)<br>

## 5. A Joint Model to Identify and Align Bilingual Named Entities
* 在一种语言中识别命名实体（该语言命名实体识别率较高，如`英语`），然后利用融合多特征的对齐模型，在另一个语言中寻找它们对应的`翻译`。这类方法虽然减少了双语命名实体识别错误的影响，但是却丢失了另一种语言中有用的命名实体信息<br>
* `双语命名实体`在没有省略翻译、或者使用简称的情况下，往往边界是统一的．因此利用双语词对齐信息可以修正命名实体识别的错误<br>
![](https://github.com/qiuxingfa/picture_/blob/master/2018.8.30/3c8b1c797b69fac7bdc6ccfa3e7cc4d.png)<br>
![](https://github.com/qiuxingfa/picture_/blob/master/2018.8.30/74b5580014ce1a84a0f9e0ea46e0abc.png)<br>
* This is because the extra words “经济” and economy are a perfect translation of each other, thus resulting in the incorrect pair {德国经济::[Germany economy]}, which receives a higher alignment score than does the correct NE pair {德国::[Germany]}.<br>
![](https://github.com/qiuxingfa/picture_/blob/master/2018.8.30/27724f1a326c0e2c7b574f2dcfec729.png)<br>
* The alignment model fails to consider the monolingual context surrounding NEs while determining NE scope, resulting in the error mentioned in Example 3.<br>
* Framework
  * (A) Initial NE Recognition, generating the initial NE anchors with off-the-shelf packages<br>
  * (B) NE Candidate Set Expansion, expanding the associated NE Candidate set to remedy the errors made in the previous stage<br>
  * (C) NE Re-identification & Alignment, extracting the final NE pairs from the Cartesian product of source and target candidate sets (created in the second stage) via a search process<br>
![](https://github.com/qiuxingfa/picture_/blob/master/2018.8.30/4c809eabb38fe5e241d318d2dfa097d.png)<br>
* 论文还没读完

## 下周计划
读相关论文，学习相关知识






